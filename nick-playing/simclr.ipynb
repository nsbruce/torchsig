{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsig.models.iq_models.efficientnet.efficientnet import efficientnet_b4\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "# from torchsig.utils.cm_plotter import plot_confusion_matrix\n",
    "from pytorch_lightning import LightningModule, Trainer\n",
    "from sklearn.metrics import classification_report\n",
    "from torchsig.datasets.sig53 import Sig53\n",
    "from torch.utils.data import DataLoader\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import optim\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torchsig.transforms as ST\n",
    "import numpy as np\n",
    "import torchsig\n",
    "import torch\n",
    "import os\n",
    "from torchvision import transforms\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Number of workers: 40\n"
     ]
    }
   ],
   "source": [
    "num_workers = os.cpu_count()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "print(f\"Number of workers: {num_workers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "### Format Dataset for Training\n",
    "Next, the datasets are then wrapped as `DataLoaders` to prepare for training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following class will return a list of 2 random transforms to apply to the network input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class ContrastiveTransformations:\n",
    "    def __init__(self, base_transforms, n_views=2):\n",
    "        self.base_transforms = base_transforms\n",
    "        self.n_views = n_views\n",
    "\n",
    "    def __call__(self, x):\n",
    "        transforms = random.sample(contrast_transforms, self.n_views)\n",
    "        return ST.Compose(transforms)(x)\n",
    "        # return [self.base_transforms(x) for _ in range(self.n_views)]\n",
    "\n",
    "contrast_transforms = [\n",
    "    ST.TimeVaryingNoise(),\n",
    "    ST.RandomPhaseShift(),\n",
    "    ST.TimeReversal(),\n",
    "    ST.RandomTimeShift(),\n",
    "    ST.TimeCrop(),\n",
    "    ST.GainDrift(),\n",
    "    ST.LocalOscillatorDrift(),\n",
    "    ST.Clip(),\n",
    "    ST.SpectralInversion()\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate Sig53 Dataset\n",
    "Here, we instantiate the Sig53 clean training dataset and the Sig53 clean validation dataset. We demonstrate how to compose multiple TorchSig transforms together, using a data impairment with a random phase shift that uniformly samples a phase offset between -1 pi and +1 pi. The next transform normalizes the complex tensor, and the final transform converts the complex data to a real-valued tensor with the real and imaginary parts as two channels. We additionally provide a target transform that maps the `SignalDescription` objects, that are part of `SignalData` objects, to a desired format for the model we will train. In this case, we use the `DescToClassIndex` target transform to map class names to their indices within an ordered class list. Finally, we sample from our datasets and print details in order to confirm functionality.\n",
    "\n",
    "For more details on the Sig53 dataset instantiations, please see the Sig53 example notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Retrieve a sample and print out information to verify\u001b[39;00m\n\u001b[1;32m     32\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;28mlen\u001b[39m(sig53_clean_train))\n\u001b[0;32m---> 33\u001b[0m data, label \u001b[38;5;241m=\u001b[39m \u001b[43msig53_clean_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset length: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mlen\u001b[39m(sig53_clean_train)))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData shape: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(data\u001b[38;5;241m.\u001b[39mshape))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchsig/datasets/sig53.py:123\u001b[0m, in \u001b[0;36mSig53.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    116\u001b[0m data: SignalData \u001b[38;5;241m=\u001b[39m SignalData(\n\u001b[1;32m    117\u001b[0m     data\u001b[38;5;241m=\u001b[39mdeepcopy(iq_data\u001b[38;5;241m.\u001b[39mtobytes()),\n\u001b[1;32m    118\u001b[0m     item_type\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mfloat64),\n\u001b[1;32m    119\u001b[0m     data_type\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39mcomplex128),\n\u001b[1;32m    120\u001b[0m     signal_description\u001b[38;5;241m=\u001b[39m[signal_desc],\n\u001b[1;32m    121\u001b[0m )\n\u001b[1;32m    122\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mT(data)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTT\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignal_description\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m data\u001b[38;5;241m.\u001b[39miq_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    125\u001b[0m sig_iq_data: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39miq_data\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torchsig/transforms/target_transforms.py:140\u001b[0m, in \u001b[0;36mDescToClassIndex.__call__\u001b[0;34m(self, signal_description)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m classes\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mclasses\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Specify Sig53 Options\n",
    "root = \"/data/torchsig-datasets/sig53/\"\n",
    "train = True\n",
    "impaired = False\n",
    "class_list = list(Sig53._idx_to_name_dict.values())\n",
    "\n",
    "target_transform = ST.DescToClassIndex(class_list=class_list)\n",
    "\n",
    "# Instantiate the Sig53 Clean Training Dataset\n",
    "sig53_clean_train = Sig53(\n",
    "    root=root, \n",
    "    train=train, \n",
    "    impaired=impaired,\n",
    "    transform=ContrastiveTransformations(contrast_transforms, n_views=2),\n",
    "    target_transform=target_transform,\n",
    "    use_signal_data=True,\n",
    ")\n",
    "\n",
    "# Instantiate the Sig53 Clean Validation Dataset\n",
    "train = False\n",
    "sig53_clean_val = Sig53(\n",
    "    root=root, \n",
    "    train=train, \n",
    "    impaired=impaired,\n",
    "    transform=ContrastiveTransformations(contrast_transforms, n_views=2),\n",
    "    target_transform=target_transform,\n",
    "    use_signal_data=True,\n",
    ")\n",
    "\n",
    "# Retrieve a sample and print out information to verify\n",
    "idx = np.random.randint(len(sig53_clean_train))\n",
    "data, label = sig53_clean_train[idx]\n",
    "print(\"Dataset length: {}\".format(len(sig53_clean_train)))\n",
    "print(\"Data shape: {}\".format(data.shape))\n",
    "print(\"Label Index: {}\".format(label))\n",
    "print(\"Label Class: {}\".format(Sig53.convert_idx_to_name(label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=sig53_clean_train,\n",
    "    batch_size=16,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    dataset=sig53_clean_val,\n",
    "    batch_size=16,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    "    drop_last=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
